{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main crRNA features to consider:\n",
    "1. Specificity (within target organism)\n",
    "2. Isoform prevalence\n",
    "3. Proximity to the N-terminus\n",
    "4. Absence of alternative start codons downstream of the cut site\n",
    "5. Avoid exon-exon boundaries\n",
    "6. Not spanning know SNP sites\n",
    "\n",
    "Other features that might stem from the preference of the Csm:\n",
    "7. No low complexity regions\n",
    "8. *Balanced GC content*\n",
    "9. No self-complementarity\n",
    "10. No target mRNA secondary structures within the binding region\n",
    "11. No crRNA secondary structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use magic for inline interactive plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gffutils\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "from Bio import SeqIO\n",
    "from collections import defaultdict, Counter\n",
    "import pickle\n",
    "from decimal import *\n",
    "import pandas as pd\n",
    "from pybedtools import BedTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create or load the GFF annotation database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "db_file = 'danRer.GRCz10.90.db'\n",
    "if not os.path.exists(db_file):\n",
    "    db = gffutils.create_db(\"Danio_rerio.GRCz10.90.gtf\",\n",
    "                            dbfn=\"danRer.GRCz10.90.db\",\n",
    "                            id_spec={'gene': 'gene_id', 'transcript': \"transcript_id\"},\n",
    "                            disable_infer_genes=True,\n",
    "                            disable_infer_transcripts=True,\n",
    "                            force=False)\n",
    "else:\n",
    "    db = gffutils.FeatureDB(db_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an indexed fasta database for faster access with SeqIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa_db = SeqIO.index_db('danRer.GRCz10.dna_sm.toplevel.idx', 'Danio_rerio.GRCz10.dna_sm.toplevel.fa', 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the variation information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gvf_fn=('danio_rerio.gvf.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def revcomp(seq):\n",
    "    # reverse complement sequence\n",
    "    \n",
    "    assert isinstance(seq, str)\n",
    "    # check if sequence is RNA\n",
    "    if seq.upper().find('U') == -1:\n",
    "        # DNA\n",
    "        comp_b = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G', 'N': 'N', \n",
    "                  'a': 't', 't': 'a', 'g': 'c', 'c': 'g', 'n': 'n'}\n",
    "    else:\n",
    "        # RNA\n",
    "        comp_b = {'A': 'U', 'U': 'A', 'G': 'C', 'C': 'G', 'N': 'N', \n",
    "                  'a': 'u', 'u': 'a', 'g': 'c', 'c': 'g', 'n': 'n'}\n",
    "    rc_seq = ''.join([comp_b[b] for b in seq][::-1])\n",
    "    return rc_seq\n",
    "\n",
    "\n",
    "def gc(seq):\n",
    "    # return gc content percentage\n",
    "    \n",
    "    assert isinstance(seq, str)\n",
    "    seq = seq.upper()\n",
    "    gc_content = 100 * Decimal(seq.count(\"G\") + seq.count(\"C\")) / len(seq)\n",
    "    return gc_content\n",
    "\n",
    "\n",
    "def transcribe(seq):\n",
    "    # transcribe sequence- change T to U\n",
    "    \n",
    "    assert isinstance(seq, str)\n",
    "    trans_seq = seq.replace('T', 'U').replace('t', 'u')\n",
    "    return trans_seq\n",
    "\n",
    "\n",
    "def revtranscribe(seq):\n",
    "    # reverse transcribe sequence- change U to T\n",
    "    \n",
    "    assert isinstance(seq, str)\n",
    "    trans_seq = seq.replace('U', 'T').replace('u', 't')\n",
    "    return trans_seq\n",
    "\n",
    "\n",
    "def get_cov(database,gene):\n",
    "    # Create genomic sequence coverage by CDS (without STOP codon).\n",
    "    \n",
    "    # get the length of the gene (1 based coords)\n",
    "    gene_length = gene.end - gene.start + 1\n",
    "    print('{} loci lenght: {!s}.'.format(gene.id, gene_length))\n",
    "    # create a numpy array of zeros with the length of the gene\n",
    "    gene_cov = np.zeros(gene_length, dtype=int)\n",
    "    for cds in db.children(gene, featuretype='CDS', order_by='start'):\n",
    "            # get relative exon coords in 0-based space\n",
    "            rel_start = cds.start - gene.start\n",
    "            rel_end = cds.end - gene.start\n",
    "            gene_cov[rel_start:rel_end + 1] += 1\n",
    "    print('Maximal genomic sequence coverage by CDS: {!s}.'.format(gene_cov.max()))\n",
    "    return gene_cov\n",
    "\n",
    "\n",
    "def get_int(gene, genomic_coverage):\n",
    "    # get the genomic intervals (for sequene retrieval)\n",
    "    \n",
    "    gen_int = []\n",
    "    cov = 0\n",
    "    start = 0 \n",
    "    for i,c in enumerate(genomic_coverage):\n",
    "        # adjust the genomic coords so they would be 0 based, non-inclusive (*similar to BED*)\n",
    "        if cov == 0 and c!=0:\n",
    "            # start cov equals zero and now it changed- store start position and coverage\n",
    "            start = i\n",
    "            cov = c\n",
    "        elif cov != 0 and c!= cov:\n",
    "            # coverage was not zero but it changed- store the previous interval , new start position and new coverage\n",
    "            gen_int += [[gene.chrom, start + gene.start - 1, i + gene.start - 1, cov]]\n",
    "            start = i\n",
    "            cov = c\n",
    "        # else if the coverage is the same- do nothing\n",
    "    # in the end store also the coverage of the last segment if the coverage was not equal to 0\n",
    "    if cov != 0:\n",
    "        gen_int += [[gene.chrom, start + gene.start - 1, i + gene.start, cov]]\n",
    "    i_cnt = Counter()\n",
    "    for e in gen_int:\n",
    "        i_cnt[e[3]] += 1\n",
    "    print('{!s} CDS coverage intervals (coverage, count): {!s}.'.format(len(gen_int), i_cnt.most_common()))\n",
    "    return gen_int\n",
    "\n",
    "\n",
    "def sub_var(intervals, variation_fn):\n",
    "    '''\n",
    "    Subtract variable sequences from the genomic intervals\n",
    "    \n",
    "    For future enhancemnt consider soft masking the whole genome beforehand or splitting the GVF file\n",
    "    on chromosomes for speed improvements.\n",
    "    '''\n",
    "    \n",
    "    # make some basic checks\n",
    "    assert os.path.exists(variation_fn)\n",
    "    assert variation_fn.endswith(('gvf', 'gvf.gz'))\n",
    "    \n",
    "    gvf_sorted_fn = 'sorted.gvf'.join(variation_fn.split('gvf'))\n",
    "    # sort the variation database for faster processing and store for further use\n",
    "    if not os.path.exists(gvf_sorted_fn):\n",
    "        print('Sorting and saving the new GVF file as {}.'.format(gvf_sorted_fn))\n",
    "        gvf_bt = BedTool(gvf_fn).sort().saveas(gvf_sorted_fn)\n",
    "    else:\n",
    "        gvf_bt = BedTool(gvf_sorted_fn)\n",
    "\n",
    "    print('Subtracting variation from {}.'.format(gvf_bt[1]['Dbxref'].split(':')[0]))\n",
    "\n",
    "    # make sure the format is right\n",
    "    for e in intervals:\n",
    "        assert len(e) == 4\n",
    "    # perform genome aritmethics\n",
    "    gi_gv = BedTool(('\\t'.join([c, str(s), str(e), '.', str(cov)]) for c,s,e,cov in intervals))\\\n",
    "    .saveas()\\\n",
    "    .subtract(gvf_bt, sorted=True, stream=True)\n",
    "\n",
    "    gi_novar = [[c, int(s), int(e), int(cov)] for c, s, e, n, cov in gi_gv]\n",
    "    return gi_novar\n",
    "\n",
    "\n",
    "def get_seq(fasta_index, intervals, coverage, length):\n",
    "    '''\n",
    "    Extract the sequences covered by all/most isoforms\n",
    "    '''    \n",
    "    \n",
    "    seg_lst = []\n",
    "    for seg in intervals:\n",
    "        #drop segments not covered by all/almost all isoforms\n",
    "        if seg[3] >= coverage:\n",
    "            #drop those that are shorter than indicated length\n",
    "            seg_len = seg[2] - seg[1]\n",
    "            if seg_len >= length:\n",
    "                #extract whole segment sequence from the fasta file (*BED-like coordinates*)\n",
    "                seg_lst.append([seg, str(fasta_index[seg[0]].seq[seg[1]:seg[2]])])\n",
    "    seg_len = 0\n",
    "    for e in seg_lst:\n",
    "        seg_len += len(e[1])\n",
    "    print('Processing {!s} nucleotides in {!s} segments.'.format(seg_len, len(seg_lst)))\n",
    "    return seg_lst\n",
    "\n",
    "\n",
    "def gen_seq(coord, sequence, length, strand, GC_lims, index=0):\n",
    "    # generate N long nucleotide streches of CDS, not containing any RepeatMasker marked low complexity regions\n",
    "    \n",
    "    while index <= len(sequence) - length:\n",
    "        seq = sequence[index:index + length]\n",
    "        # generate reverse complement, transcribed sequences, depending on gene strand\n",
    "        if strand == '+':\n",
    "            rna_seq = transcribe(revcomp(seq))\n",
    "        else:\n",
    "            rna_seq = transcribe(seq)\n",
    "        s_coords = [coord[0],coord[1] + index, coord[1] + index + length]\n",
    "        index +=1\n",
    "        # drop the sequence when outside of the GC content limits\n",
    "        gc_content = round(gc(rna_seq), 2)\n",
    "        if gc_content < GC_lims[0] or gc_content > GC_lims[1]:\n",
    "            continue\n",
    "        # do not generate sequences with soft masked nucleotides\n",
    "        if rna_seq.isupper():\n",
    "            yield [s_coords, rna_seq, gc_content]\n",
    "    return\n",
    "\n",
    "\n",
    "def count_seq(segments, length, GC_lims):\n",
    "    # count the number of sequences for processing\n",
    "    \n",
    "    GC_high = 0\n",
    "    GC_low = 0\n",
    "    sm_droped = 0\n",
    "    good = 0\n",
    "    for coord, sequence in segments:\n",
    "        index = 0\n",
    "        while index <= len(sequence) - length:\n",
    "            seq = sequence[index:index + length]\n",
    "            index +=1\n",
    "            # count the sequence when outside of the GC content limits\n",
    "            gc_content = round(gc(seq), 2)\n",
    "            if gc_content < GC_lims[0]:\n",
    "                GC_low += 1\n",
    "                continue\n",
    "            if gc_content > GC_lims[1]:\n",
    "                GC_high += 1\n",
    "                continue\n",
    "            # count sequences with soft masked nucleotides\n",
    "            if seq.isupper():\n",
    "                good += 1\n",
    "            else:\n",
    "                sm_droped += 1\n",
    "    total = GC_high + GC_low + sm_droped + good\n",
    "    print('Valid sequences: {} / {} (GC_low = {}, GC_high = {}, sm = {})'.format(good,\n",
    "                                                                                 total, \n",
    "                                                                                 GC_low, \n",
    "                                                                                 GC_high, \n",
    "                                                                                 sm_droped))\n",
    "    return good\n",
    "\n",
    "\n",
    "def run_RNAcofold(seq):\n",
    "    # Run RNAcofold to estimate the duplex folding change in free energy\n",
    "    \n",
    "    in_str = seq + '&' + seq\n",
    "    params = ['-a0',\n",
    "              '-d2',\n",
    "              '--noLP',\n",
    "              '--noPS',\n",
    "              '--output-format=D',\n",
    "              '--csv-noheader']\n",
    "    \n",
    "    proc = subprocess.run(['RNAcofold'] + params,\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          input=in_str,\n",
    "                          encoding='ascii')\n",
    "    if proc.returncode != 0:\n",
    "        print(proc.stderr)\n",
    "        proc.check_returncode()\n",
    "    else:\n",
    "        result = proc.stdout.split(',')\n",
    "        en = {'dG':Decimal(result[7]),\n",
    "              'AB':Decimal(result[8]),\n",
    "              'AA':Decimal(result[9]),\n",
    "              'BB':Decimal(result[10]),\n",
    "              'A':Decimal(result[11]),\n",
    "              'B':Decimal(result[12])}\n",
    "        return en\n",
    "\n",
    "    \n",
    "def get_tmpfs():\n",
    "    '''\n",
    "    Helper function to to pick tmpfs folder and check if it exists on different OSes.\n",
    "    \n",
    "    Might need to be developed further.\n",
    "    '''\n",
    "    \n",
    "    tmp_dir = os.path.join('/dev', 'shm')\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        tmp_dir = os.path.join('/run', 'shm')\n",
    "    assert os.path.exists(tmp_dir)\n",
    "    return tmp_dir\n",
    "    \n",
    "    \n",
    "def run_RNAfold(transcript_id, transcript_seq):\n",
    "    \n",
    "    params = ['-p1',\n",
    "              '-d2',\n",
    "              '--noLP',\n",
    "              '--noPS']\n",
    "    \n",
    "    in_str = '>{}\\n'.format(transcript_id) + transcript_seq\n",
    "    \n",
    "    tmp_dir = get_tmpfs()\n",
    "    \n",
    "    proc1 = subprocess.run(['RNAfold'] + params,\n",
    "                           stdout=subprocess.DEVNULL,\n",
    "                           stderr=subprocess.PIPE,\n",
    "                           input=in_str,\n",
    "                           encoding='ascii',\n",
    "                           cwd=tmp_dir)\n",
    "    if proc1.returncode != 0:\n",
    "        print(proc1.stderr)\n",
    "        proc1.check_returncode()\n",
    "    \n",
    "    out_fn = os.path.join(tmp_dir, transcript_id + '_dp.ps')\n",
    "    assert os.path.exists(out_fn)\n",
    "    \n",
    "    proc2 = subprocess.run(['mountain.pl', out_fn],\n",
    "                           stderr=subprocess.PIPE,\n",
    "                           stdout=subprocess.PIPE,\n",
    "                           cwd=tmp_dir)\n",
    "    if proc2.returncode != 0:\n",
    "        print(proc2.stderr)\n",
    "        proc2.check_returncode()\n",
    "    else:\n",
    "        data = proc2.stdout.decode('ascii').split('\\n')\n",
    "        elements = [e.split() for e in data]\n",
    "        mark = []\n",
    "        for i, position in enumerate(elements):\n",
    "                if position != [] and position[0] == '&':\n",
    "                    mark.append(i)\n",
    "        energy = [Decimal(v) for k, v in elements[mark[1] + 1 :-1]]\n",
    "        return energy\n",
    "\n",
    "    \n",
    "def get_trans(database, fasta_index, gene):\n",
    "    '''\n",
    "    Obtain transcript sequences\n",
    "    \n",
    "    TODO: with biopython this is slow, as it accesses the fasta file from the begining of each record\n",
    "    for each exon of every transcript and needs a future rewrite\n",
    "    \n",
    "    For speed, use:\n",
    "    blastdbcmd -entry [tr.id, tr['transcript_version']] -db danRer_e91_allrna\n",
    "    '''\n",
    "    \n",
    "    for transcript in db.children(gene, featuretype='transcript', order_by='start'):\n",
    "        if transcript['transcript_biotype'][0] == 'protein_coding':\n",
    "            trans_seq = None\n",
    "            for exon in db.children(transcript, featuretype='exon', order_by='start'):\n",
    "                if not trans_seq:\n",
    "                    trans_seq = str(fasta_index[transcript.chrom].seq[exon.start - 1:exon.end])\n",
    "                else:\n",
    "                    trans_seq += str(fasta_index[transcript.chrom].seq[exon.start - 1:exon.end])\n",
    "            if transcript.strand == '-':\n",
    "                trans_seq = revcomp(trans_seq)\n",
    "            yield transcript.id, trans_seq\n",
    "    return\n",
    "\n",
    "\n",
    "def pick_transcript(database, fasta_index, gene=None, eid=None):\n",
    "    '''\n",
    "    Pick only the longest from protein coding, preferably havana/ensembl+havana annotated transcripts \n",
    "    and return it's id and sequence;\n",
    "    if ensembl id is provided by user return sequence of that particular one.\n",
    "    '''\n",
    "    \n",
    "    if not eid:\n",
    "        print('No transcript Ensemble ID specified.\\nPicking the longest, \\\n",
    "preferably HAVANA annotated transcript for free energy calculations.')\n",
    "        max_len = 0\n",
    "        max_id = None\n",
    "        max_exons = None\n",
    "        max_source = None\n",
    "        for transcript in db.children(gene, featuretype='transcript', order_by='start'):\n",
    "            if transcript['transcript_biotype'][0] == 'protein_coding':\n",
    "                t_len = 0\n",
    "                t_id = transcript.id\n",
    "                t_exo = []\n",
    "                t_sou = transcript['transcript_source'][0]\n",
    "                for exon in db.children(transcript, featuretype='exon', order_by='start'):\n",
    "                    # calculate the transcript lenght from it's exons' lenght, store the exons' coords, \n",
    "                    # do not extract the sequence yet\n",
    "                    t_len += exon.end - exon.start + 1\n",
    "                    t_exo.append((exon.start - 1, exon.end))\n",
    "                if t_len > max_len and ((max_source == 'ensembl' or max_source == None) or\\\n",
    "                (t_sou == 'havana' or t_sou == 'ensembl_havana')):\n",
    "                    max_len = t_len\n",
    "                    max_id = t_id\n",
    "                    max_exons = t_exo\n",
    "                    max_source = t_sou\n",
    "                elif max_source == 'ensembl' and (t_sou == 'havana' or t_sou == 'ensembl_havana'):\n",
    "                    # prefer havana annotated transcripts\n",
    "                    max_len = t_len\n",
    "                    max_id = t_id\n",
    "                    max_exons = t_exo\n",
    "                    max_source = t_sou\n",
    "                elif t_len == max_len and t_sou != max_source:\n",
    "                    # if by chance two transcripts are of equal lenght pick the one with merged annotation\n",
    "                    # if both have the same annotation source keep the first one\n",
    "                    if t_sou == 'ensembl_havana':\n",
    "                        max_len = t_len\n",
    "                        max_id = t_id\n",
    "                        max_exons = t_exo\n",
    "                        max_source = t_sou\n",
    "                elif t_len == max_len:\n",
    "                    print('W: Discarding transcript {}, source: {}, of equal length: {!s} to {}'.format(t_id, \n",
    "                                                                                                       t_sou, \n",
    "                                                                                                       t_len,\n",
    "                                                                                                       max_id))\n",
    "        print('Target: {}, source: {}, length: {!s}'.format(max_id, max_source, max_len))\n",
    "        max_seq = None\n",
    "        for exon_coord in max_exons:\n",
    "            if not max_seq:\n",
    "                max_seq = str(fasta_index[gene.chrom].seq[exon_coord[0]:exon_coord[1]])\n",
    "            else:\n",
    "                max_seq += str(fasta_index[gene.chrom].seq[exon_coord[0]:exon_coord[1]])\n",
    "        if gene.strand == '-':\n",
    "            max_seq = revcomp(max_seq)\n",
    "        return max_id, max_seq\n",
    "    else:\n",
    "        transcript = db[eid]\n",
    "        trans_seq = None\n",
    "        for exon in db.children(transcript, featuretype='exon', order_by='start'):\n",
    "            if not trans_seq:\n",
    "                trans_seq = str(fasta_index[transcript.chrom].seq[exon.start - 1:exon.end])\n",
    "            else:\n",
    "                trans_seq += str(fasta_index[transcript.chrom].seq[exon.start - 1:exon.end])\n",
    "        if transcript.strand == '-':\n",
    "            trans_seq = revcomp(trans_seq)\n",
    "        print('Target: {}, source: {}, length: {!s}'.format(transcript.id, transcript['transcript_source'][0], len(trans_seq)))\n",
    "        return transcript.id, trans_seq\n",
    "    \n",
    "    \n",
    "def create_negseqidlst(database, gene_id=None, transcript_id=None):\n",
    "    '''\n",
    "    Create temporary file with transcript id's to exclude from blast searches.\n",
    "    \n",
    "    When transcript Id is given, list all transcripts of the parent gene.\n",
    "    '''\n",
    "    \n",
    "    g_id = gene_id\n",
    "    if transcript_id:\n",
    "        g_id = database[transcript_id]['gene_id'][0]\n",
    "    \n",
    "    gene = database[g_id]\n",
    "    \n",
    "    ngsi = ''\n",
    "    for i,f in enumerate(database.children(gene, featuretype='transcript')):\n",
    "        if i == 0:\n",
    "            ngsi += '.'.join([f.id, f['transcript_version'][0]])\n",
    "        else:\n",
    "            ngsi += '\\n' + '.'.join([f.id, f['transcript_version'][0]])\n",
    "\n",
    "    tmp_fn = g_id + '.balst.ngsi.lst'\n",
    "    tmp_file = os.path.join(get_tmpfs(), tmp_fn)\n",
    "    with open(tmp_file, 'w') as handle:\n",
    "        handle.write(ngsi)\n",
    "    return tmp_file\n",
    "\n",
    "\n",
    "def blast_it(sequence, tmp_file=None):\n",
    "    '''\n",
    "    Run blastn on a sequence (wordsize 7).\n",
    "    Return Bitscore, nident\n",
    "    \n",
    "    *Might* be faster to run on all sequences beforehand.\n",
    "    '''\n",
    "    \n",
    "    assert isinstance(sequence, str)\n",
    "\n",
    "    params = ['-task', 'blastn',\n",
    "              '-word_size', '7',\n",
    "              '-db', './blastdb/danRer_e91_allrna',\n",
    "              '-outfmt', '6 bitscore nident',\n",
    "              '-num_threads', '1',\n",
    "              '-max_target_seqs', '1']\n",
    "    if tmp_file:\n",
    "        params += ['-negative_seqidlist', tmp_file]\n",
    "\n",
    "    proc = subprocess.run(['blastn',\n",
    "                           '-query', '-',\n",
    "                           '-out', '-'] + params,\n",
    "                          stdout=subprocess.PIPE,\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          input=sequence,\n",
    "                          encoding='ascii')\n",
    "\n",
    "    if proc.returncode != 0:\n",
    "        print(proc.stderr)\n",
    "        proc.check_returncode()\n",
    "    else:\n",
    "        b_out = proc.stdout.split()\n",
    "        if len(b_out) == 0:\n",
    "            bitscore = -1\n",
    "            nident = 0\n",
    "            return bitscore, nident\n",
    "        else:\n",
    "            bitscore = float(b_out[0])\n",
    "            nident = int(b_out[1])\n",
    "            return bitscore, nident\n",
    "\n",
    "        \n",
    "def feed_fun(segments, length, strand, GC_lims, transcript_seq, entropy, tmp_path=None):\n",
    "    for coordinates, sequence in segments:\n",
    "        for result in gen_seq(coordinates, sequence, length,\n",
    "                              strand, GC_lims, index=0):\n",
    "            yield result + [transcript_seq] + [tmp_path] + [entropy]\n",
    "    return\n",
    "\n",
    "\n",
    "def processing_fun(input_list):\n",
    "    coords, c_seq, gc_content, t_seq, ngsi_tmp, entropy = input_list\n",
    "    # get the mean entropy of the target sequence\n",
    "    # TODO: !!! this is far from perfect\n",
    "    # t_seq.upper() required in case of working with user-input and targeting soft masked sequence \n",
    "    c_start = t_seq.upper().find(revcomp(revtranscribe(c_seq)))\n",
    "    assert c_start != -1, 'Target sequence not found: {}'.format(revcomp(revtranscribe(c_seq)))\n",
    "    c_pos_ent = entropy[c_start:c_start + len(c_seq)]\n",
    "    c_mean_ent = sum(c_pos_ent) / len(c_pos_ent)\n",
    "    # estimate also the change in free energy of monomer binding to itself,\n",
    "    energy = run_RNAcofold(c_seq)\n",
    "    dG_AA = energy['dG']\n",
    "    G_A = energy['A']\n",
    "    # blast the sequence against the Danio rerio RNA database\n",
    "    bs, ni = blast_it(c_seq, ngsi_tmp)\n",
    "    return coords, c_seq, gc_content, c_mean_ent, dG_AA, G_A, bs, ni\n",
    "    \n",
    "    \n",
    "def estimate_energy_all(database, fasta_index, gene, intervals, coverage, length, GC_lims, proc=1):\n",
    "    '''\n",
    "    Estimate free energy change for each segment for all transcripts- very inefficient\n",
    "    for 3 isoforms and ~500 segments takes ~10-12h on 4 procesors/ 7 threads.\n",
    "    '''\n",
    "    \n",
    "    pool = Pool(proc)\n",
    "    strand = gene.strand\n",
    "    segments = get_seq(fasta_index, intervals, coverage, length)\n",
    "    result_dict = defaultdict(list)\n",
    "    for transcript_id, transcript_seq in get_trans(database, fasta_index, gene):\n",
    "        iterator = feed_fun(segments, length, strand, GC_lims, transcript_seq)\n",
    "        for result in pool.imap_unordered(processing_fun, iterator,\n",
    "                                          chunksize=1):\n",
    "            coords, c_seq, gc_content, dG, dG_AA = result\n",
    "            if coords not in result_dict[coords[1]]:\n",
    "                result_dict[coords[1]].append(coords)\n",
    "            if c_seq not in result_dict[coords[1]]:\n",
    "                result_dict[coords[1]].append(c_seq)\n",
    "            if gc_content not in result_dict[coords[1]]:\n",
    "                result_dict[coords[1]].append(gc_content)\n",
    "            if ('AA', dG_AA) not in result_dict[coords[1]]:\n",
    "                result_dict[coords[1]].append(('AA', dG_AA))\n",
    "            result_dict[coords[1]].append((transcript_id, dG))\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def estimate_energy(database, fasta_index, gene, intervals, coverage, length, GC_lims, ensembl_id=None, proc=1):\n",
    "    '''\n",
    "    Estimate free energy change for a single transcript\n",
    "    '''\n",
    "    \n",
    "    pool = Pool(proc)\n",
    "    strand = gene.strand\n",
    "    segments = get_seq(fasta_index, intervals, coverage, length)\n",
    "    total = count_seq(segments, length, GC_lims)\n",
    "    ngsi_tmp = create_negseqidlst(database, gene_id=gene.id)\n",
    "    result_list = []\n",
    "    transcript_id, transcript_seq = pick_transcript(database, fasta_index, gene, ensembl_id)\n",
    "    # get the positional entropy for the whole transcript\n",
    "    entropy = run_RNAfold(transcript_id, transcript_seq)\n",
    "    iterator = feed_fun(segments, length, strand, GC_lims, transcript_seq, entropy, ngsi_tmp)\n",
    "    done = 0\n",
    "    for result in pool.imap_unordered(processing_fun, iterator,\n",
    "                                      chunksize=1):\n",
    "        done += 1\n",
    "        progress = str(done) + '/' + str(total)\n",
    "        percent = str(round(100 * Decimal(done) / Decimal(total), 1)) + '%'\n",
    "        out = '{} ({})'.format(progress, percent)\n",
    "        print(out, end='', flush=True)\n",
    "        print('\\r', end='')\n",
    "        result_list.append(result)\n",
    "    # clean up\n",
    "    # blast negative seqid list file\n",
    "    os.remove(ngsi_tmp)\n",
    "    # RNAfold dot plot PS file\n",
    "    os.remove(os.path.join(get_tmpfs(), transcript_id + '_dp.ps'))\n",
    "    return result_list\n",
    "\n",
    "\n",
    "def processing_input(string):\n",
    "    '''\n",
    "    Process the input sequence and return the elements needed for further steps.\n",
    "    '''\n",
    "    \n",
    "    # quick checks\n",
    "    assert isinstance(string, str), 'Input not a srting.'\n",
    "    # take care of whitespaces\n",
    "    sequence = string.strip()\n",
    "    assert sequence.upper().startswith(('>', 'A', 'G', 'C', 'T')), 'Input not a DNA sequence in FASTA format or PLAIN.'\n",
    "    \n",
    "    # if fasta, get the sequence id from the header\n",
    "    if sequence.startswith('>'):\n",
    "        id_line, seq = sequence.split('\\n', maxsplit=1)\n",
    "        seq_id = id_line.lstrip('>').split()[0]\n",
    "    else:\n",
    "        seq_id = 'plain'\n",
    "        seq = sequence\n",
    "    \n",
    "    # join all the lines if present, also taking care of whitespaces\n",
    "    seq = ''.join(l.strip() for l in seq.split('\\n'))\n",
    "                          \n",
    "    return seq_id, seq\n",
    "\n",
    "\n",
    "def check_segid(database, input_id):\n",
    "    '''\n",
    "    Helper function to check if the sequence ID is valid for negative seqid list file creation.\n",
    "    \n",
    "    Will have to be developed further.\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        feature = database[input_id]\n",
    "    except gffutils.FeatureNotFoundError:\n",
    "        print('Feature \\'{}\\' not found in the database.'.format(input_id))\n",
    "        return False\n",
    "    else:\n",
    "        if feature.featuretype == 'transcript':\n",
    "            return True\n",
    "        else:\n",
    "            print('\\'{}\\' is not a valid Transcript ID.'.format(input_id))\n",
    "            return False\n",
    "    \n",
    "\n",
    "def estimate_energy_input(input_sequence, length, GC_lims, strand='+', database=None, fasta_index=None, proc=1):\n",
    "    '''\n",
    "    Estimate free energy change for a single transcript.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    strand- use if input is genomic sequence\n",
    "    database; fasta_index - must be provided if database Transcript ID lookup is required\n",
    "    '''\n",
    "    \n",
    "    pool = Pool(proc)\n",
    "    input_id, input_seq = processing_input(input_sequence)\n",
    "    # assume that for the input the strand is always the Watson one\n",
    "    segment = [[['.', 0, len(input_seq)], input_seq]]\n",
    "    total = count_seq(segment, length, GC_lims)\n",
    " \n",
    "    ngsi_tmp = None\n",
    "    # check if the input ID is in the database and if it is a valid transcript ID, if yes use it to create\n",
    "    # negative segid list for blast and fold this particular transcript for energy estimations\n",
    "    if database and fasta_index and check_segid(database, input_id):\n",
    "        ngsi_tmp = create_negseqidlst(database, transcript_id=input_id)\n",
    "        transcript_id, transcript_seq = pick_transcript(database, fasta_index, eid=input_id)\n",
    "    else:\n",
    "        print('Using the provided sequence for free energy calculation.')\n",
    "        transcript_id, transcript_seq = input_id, input_seq\n",
    "\n",
    "    result_list = []\n",
    "    # get the positional entropy for the whole sequence/transcript\n",
    "    entropy = run_RNAfold(transcript_id, transcript_seq)\n",
    "    iterator = feed_fun(segment, length, strand, GC_lims, transcript_seq, entropy, ngsi_tmp)\n",
    "    done = 0\n",
    "    for result in pool.imap_unordered(processing_fun, iterator,\n",
    "                                      chunksize=1):\n",
    "        done += 1\n",
    "        progress = str(done) + '/' + str(total)\n",
    "        percent = str(round(100 * Decimal(done) / Decimal(total), 1)) + '%'\n",
    "        out = '{} ({})'.format(progress, percent)\n",
    "        print(out, end='', flush=True)\n",
    "        print('\\r', end='')\n",
    "        result_list.append(result)\n",
    "    # clean up\n",
    "    # blast negative seqid list file\n",
    "    if ngsi_tmp:\n",
    "        os.remove(ngsi_tmp)\n",
    "    # RNAfold dot plot PS file\n",
    "    os.remove(os.path.join(get_tmpfs(), transcript_id + '_dp.ps'))\n",
    "    return result_list\n",
    "\n",
    "\n",
    "def main(database, fasta_index, var_db, target_lst, crRNA_lenght, GC_limit, n_threads, coverage_limit='max'):\n",
    "    '''\n",
    "    Main function to run the program.\n",
    "    '''\n",
    "    \n",
    "    result = []\n",
    "    for target in target_lst:\n",
    "        print('\\n---\\n')\n",
    "        gene = database[target]\n",
    "        g_name = gene['gene_name'][0]\n",
    "        print(g_name)\n",
    "        gene_cov = get_cov(database, gene)\n",
    "        cov_lims = coverage_limit\n",
    "        if coverage_limit == 'max':\n",
    "            cov_lims = gene_cov.max()\n",
    "        if gene.strand == '+':\n",
    "            plot_cov = gene_cov\n",
    "        else:\n",
    "            plot_cov = gene_cov[::-1]\n",
    "        plt.plot(plot_cov, 'blue')\n",
    "        plt.show()\n",
    "        gen_int = sub_var(get_int(gene, gene_cov), var_db)\n",
    "        output = estimate_energy(database,\n",
    "                                 fasta_index,\n",
    "                                 gene,\n",
    "                                 gen_int,\n",
    "                                 cov_lims,\n",
    "                                 crRNA_len,\n",
    "                                 GC_limit,\n",
    "                                 proc=n_threads)\n",
    "\n",
    "        fn = target + '.result.csv'\n",
    "        print('\\nWritting file {}.'.format(fn))\n",
    "        with open(fn, 'w') as handle:\n",
    "            for item in output:\n",
    "                handle.write(','.join([str(e) for e in item]) + '\\n')\n",
    "\n",
    "        result.append((g_name, output))\n",
    "        print('\\nDone.')\n",
    "    return result\n",
    "\n",
    "\n",
    "def prepare_output(result, n_store=50, write=True):\n",
    "    '''\n",
    "    Prepare the data frames, score and store the output.\n",
    "    '''\n",
    "    \n",
    "    final_dict = {}\n",
    "    for name, output in result:\n",
    "\n",
    "        labels = ['coords', 'seq', 'GC', 'ent', 'dG_AA', 'G_A', 'bitscore', 'nident']\n",
    "        df = pd.DataFrame.from_records(output, columns=labels)\n",
    "        df[['chr', 'start', 'end']] = pd.DataFrame([e for e in df['coords']])\n",
    "        del df['coords']\n",
    "\n",
    "        # reset index to match the start position (shifted by multiprocessing)\n",
    "        df = df.sort_values('start').reset_index(drop=True)\n",
    "        \n",
    "        score = []\n",
    "        df = df.sort_values('ent', ascending=False)\n",
    "        points = {}\n",
    "        point = 1\n",
    "        for e in df['ent'].unique():\n",
    "            points[e] = point\n",
    "            point += 1\n",
    "        for e in df['ent']:\n",
    "            score.append(points[e])\n",
    "        score\n",
    "        df['score'] = score\n",
    "\n",
    "        blast_score = []\n",
    "        blast_points = {}\n",
    "        df = df.sort_values('bitscore')\n",
    "        num_uniq_bits = len(df['bitscore'].unique())\n",
    "        point_step = Decimal(max(points.values())) / num_uniq_bits\n",
    "        blast_point = point_step\n",
    "        for e in df['bitscore'].unique():\n",
    "            blast_points[e] = blast_point\n",
    "            blast_point += point_step\n",
    "        for e in df['bitscore']:\n",
    "            blast_score.append(blast_points[e])\n",
    "        df['score'] += blast_score\n",
    "\n",
    "        df = df.sort_values('score')\n",
    "        \n",
    "        if n_store <= 0:\n",
    "            final_dict[name] = df\n",
    "        else:\n",
    "            final_dict[name] = df.head(n_store)\n",
    "    if write:\n",
    "        for key in final_dict:\n",
    "            xlsx_fn = key + '.csm.xlsx'\n",
    "            print('Writing file {}.'.format(xlsx_fn))\n",
    "            final_dict[key].to_excel(xlsx_fn)\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "#TODO: things to consider when doing a rewrite\n",
    "# -- minor gain would be to run RNAcofold -p instead of -a and not calculate the dG of AA complex formation\n",
    "\n",
    "## round it to 2 decimals\n",
    "#    dG_AA = round(cofold_dict['AA'] - cofold_dict['A'] * 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTER AN ENSEMBLE GENE ID HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gene = db['ENSDARG00000008454']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create genomic sequence coverage by **CDS** (without STOP codon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_cov = get_cov(db, gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ploting change start coordinates to local and reverse the coverage if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if gene.strand == '+':\n",
    "    plot_cov = gene_cov\n",
    "else:\n",
    "    plot_cov = gene_cov[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(plot_cov, 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the genomic intervals for sequene retrieval. Subtract the varable sequences comming from dbSNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_int = sub_var(get_int(gene,gene_cov), gvf_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define search parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crRNA_len = 36\n",
    "GC_limit = (40,60)\n",
    "# number of processors to use\n",
    "n_threads = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = ['ENSDARG00000008454', \n",
    "           'ENSDARG00000012389',\n",
    "           'ENSDARG00000101576',\n",
    "           'ENSDARG00000014373',\n",
    "           'ENSDARG00000035095',\n",
    "           'ENSDARG00000017821']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = main(db, fa_db, gvf_fn, targets, crRNA_len, GC_limit, n_threads, coverage_limit='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "formated = prepare_output(out, n_store=0, write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "formated['ta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode for working on user given sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "egfp_seq = 'aggatccaccggtcgccaccatggtgagcaagggcgaggagctgttcaccggggtggtgcccatcctggtcgagctggacggcgacgtaaacggccacaagttcagcgtgtccggcgagggcgagggcgatgccacctacggcaagctgaccctgaagttcatctgcaccaccggcaagctgcccgtgccctggcccaccctcgtgaccaccctgacctacggcgtgcagtgcttcagccgctaccccgaccacatgaagcagcacgacttcttcaagtccgccatgcccgaaggctacgtccaggagcgcaccatcttcttcaaggacgacggcaactacaagacccgcgccgaggtgaagttcgagggcgacaccctggtgaaccgcatcgagctgaagggcatcgacttcaaggaggacggcaacatcctggggcacaagctggagtacaactacaacagccacaacgtctatatcatggccgacaagcagaagaacggcatcaaggtgaacttcaagatccgccacaacatcgaggacggcagcgtgcagctcgccgaccactaccagcagaacacccccatcggcgacggccccgtgctgctgcccgacaaccactacctgagcacccagtccgccctgagcaaagaccccaacgagaagcgcgatcacatggtcctgctggagttcgtgaccgccgccgggatcactctcggcatggacgagctgtacaagtaaagcggccgc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid sequences: 714 / 714 (GC_low = 0, GC_high = 0, sm = 0)\n",
      "Using the provided sequence for free energy calculation.\n",
      "714/714 (100.0%)\r"
     ]
    }
   ],
   "source": [
    "egfp_res = estimate_energy_input(egfp_seq.upper(), 36, (0,100), proc=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file eGFP.csm.xlsx.\n"
     ]
    }
   ],
   "source": [
    "egfp_out = prepare_output([('eGFP', egfp_res)], n_store=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>GC</th>\n",
       "      <th>ent</th>\n",
       "      <th>dG_AA</th>\n",
       "      <th>G_A</th>\n",
       "      <th>bitscore</th>\n",
       "      <th>nident</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>AUGCGGUUCACCAGGGUGUCGCCCUCGAACUUCACC</td>\n",
       "      <td>61.11</td>\n",
       "      <td>1.411554944444444444444444444</td>\n",
       "      <td>-10.52</td>\n",
       "      <td>-11.306073</td>\n",
       "      <td>28.3</td>\n",
       "      <td>18</td>\n",
       "      <td>.</td>\n",
       "      <td>355</td>\n",
       "      <td>391</td>\n",
       "      <td>166.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>CACGAGGGUGGGCCAGGGCACGGGCAGCUUGCCGGU</td>\n",
       "      <td>75.00</td>\n",
       "      <td>1.345367777777777777777777778</td>\n",
       "      <td>-9.36</td>\n",
       "      <td>-10.663815</td>\n",
       "      <td>28.3</td>\n",
       "      <td>18</td>\n",
       "      <td>.</td>\n",
       "      <td>170</td>\n",
       "      <td>206</td>\n",
       "      <td>188.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>ACGAGGGUGGGCCAGGGCACGGGCAGCUUGCCGGUG</td>\n",
       "      <td>75.00</td>\n",
       "      <td>1.3156325</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>-10.650033</td>\n",
       "      <td>28.3</td>\n",
       "      <td>18</td>\n",
       "      <td>.</td>\n",
       "      <td>169</td>\n",
       "      <td>205</td>\n",
       "      <td>199.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>CGAGGGUGGGCCAGGGCACGGGCAGCUUGCCGGUGG</td>\n",
       "      <td>77.78</td>\n",
       "      <td>1.262398333333333333333333333</td>\n",
       "      <td>-7.76</td>\n",
       "      <td>-11.742355</td>\n",
       "      <td>28.3</td>\n",
       "      <td>17</td>\n",
       "      <td>.</td>\n",
       "      <td>168</td>\n",
       "      <td>204</td>\n",
       "      <td>224.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>AGCAGGACCAUGUGAUCGCGCUUCUCGUUGGGGUCU</td>\n",
       "      <td>58.33</td>\n",
       "      <td>1.261723222222222222222222222</td>\n",
       "      <td>-9.56</td>\n",
       "      <td>-7.146165</td>\n",
       "      <td>28.3</td>\n",
       "      <td>18</td>\n",
       "      <td>.</td>\n",
       "      <td>649</td>\n",
       "      <td>685</td>\n",
       "      <td>225.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      seq     GC  \\\n",
       "355  AUGCGGUUCACCAGGGUGUCGCCCUCGAACUUCACC  61.11   \n",
       "170  CACGAGGGUGGGCCAGGGCACGGGCAGCUUGCCGGU  75.00   \n",
       "169  ACGAGGGUGGGCCAGGGCACGGGCAGCUUGCCGGUG  75.00   \n",
       "168  CGAGGGUGGGCCAGGGCACGGGCAGCUUGCCGGUGG  77.78   \n",
       "649  AGCAGGACCAUGUGAUCGCGCUUCUCGUUGGGGUCU  58.33   \n",
       "\n",
       "                               ent   dG_AA         G_A  bitscore  nident chr  \\\n",
       "355  1.411554944444444444444444444  -10.52  -11.306073      28.3      18   .   \n",
       "170  1.345367777777777777777777778   -9.36  -10.663815      28.3      18   .   \n",
       "169                      1.3156325   -7.69  -10.650033      28.3      18   .   \n",
       "168  1.262398333333333333333333333   -7.76  -11.742355      28.3      17   .   \n",
       "649  1.261723222222222222222222222   -9.56   -7.146165      28.3      18   .   \n",
       "\n",
       "     start  end  score  \n",
       "355    355  391  166.8  \n",
       "170    170  206  188.8  \n",
       "169    169  205  199.8  \n",
       "168    168  204  224.8  \n",
       "649    649  685  225.8  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egfp_out['eGFP'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Csm-gf6UZX-p",
   "language": "python",
   "name": "csm-gf6uzx-p"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
